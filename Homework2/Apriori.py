"""
Authors: Chengyang Huang, Ziheng Zhang
Course:  ID2222 Data Mining
"""

import collections
import itertools
import typing

import apriori_utils as utl


class APriori:
    def __init__(self, file_path, min_support, min_confidence):
        self.file_path = file_path
        self.min_support = min_support
        self.min_confidence = min_confidence

        """
        é¢„å¤„ç†æ¯ä¸ªå…ƒç´ åœ¨ç¬¬å‡ è¡Œ
        dict: key=item, value=line_number
        e.g. item2line_index[1] = (0, 1 ,2) è¡¨ç¤ºå…ƒç´  1 åœ¨ç¬¬ 0, 1, 2 è¡Œå‡ºç°è¿‡
        """
        self.item2line_index = collections.defaultdict(set)
        self.total_line = 1  # æ€»å…±è¿™ä¹ˆå¤šè¡Œ
        with open(self.file_path) as f:
            for line in f:
                line_tuple = ()
                for i in line.strip().split(' '):
                    line_tuple += (i,)
                    self.item2line_index[i].add(self.total_line)
                self.total_line += 1
        f.close()
        self.total_line -= 1

    def items_index(self, itemset):
        itemset = sorted(itemset, key=lambda item: len(self.item2line_index[item]), reverse=True)

        item = itemset.pop()
        index = self.item2line_index[item]
        support = len(index) / self.total_line

        # frequent set ä¸­çš„å…ƒç´ å¿…é¡»æ¯ä¸ªéƒ½æ»¡è¶³è¦æ±‚
        if support < self.min_support:
            return False, None, support

        while itemset:
            item = itemset.pop()

            # ä¸¤ä¸ªå…ƒç´ å…±åŒå‡ºç°åœ¨äº†å“ªäº›è¡Œ, å¹¶ä¸”åˆ¤æ–­æ˜¯å¦æ»¡è¶³è¦æ±‚
            index = index.intersection(self.item2line_index[item])
            support = len(index) / self.total_line
            if support < self.min_support:
                return False, None, support

        return True, index, support

    def gen_rules(self, frequent_items: tuple):
        """
        å…ˆå¾—åˆ° k-frequent-set, ç„¶åç”Ÿæˆ rules.
        
        (ä»£ç å†™çš„æ¯”è¾ƒä¸‘ :D, æ„Ÿè§‰å†™çš„æ˜¯å¯¹çš„, ä¸ç¡®å®š...ğŸ«¤)
        (æ—¶é—´å¤æ‚åº¦è²Œä¼¼æ˜¯ O(n^2) çš„, n æ˜¯ k-frequent-set çš„å¤§å°, ä½† k-frequent-set æœ¬èº«å°±ä¸å¤§, æ‰€ä»¥è·‘èµ·æ¥ä¸æ˜¯å¾ˆæ…¢...)
        (å¦‚æœå†™é”™äº†, å°±ç›´æ¥åˆ äº†å§ ğŸ¥¹)

        e.g. rule: lhs => rhs
        lhs: left hand side, è¡¨ç¤ºè§„åˆ™å·¦è¾¹çš„éƒ¨åˆ†
        rhs: right hand side, è¡¨ç¤ºè§„åˆ™å³è¾¹çš„éƒ¨åˆ†

        ç”¨ bfs å»æœæœ‰å“ªäº›è§„åˆ™ >= min_confidence

        é¦–å…ˆæšä¸¾ rhs å¤§å°ä¸º 1 çš„æ—¶å€™, æ¯”å¦‚ 3-frequent-set = {1, 2, 3}, é‚£ä¹ˆå¯ä»¥æšä¸¾å‡ºè§„åˆ™ (1, 2) => (3), (1, 3) => (2), etc.
        æœ‰äº† rhs ä¹‹å, lhs å°±æ˜¯æ•´ä¸ªé›†åˆå‡å» rhs.

        ç„¶åè®¡ç®—è¿™ä¸ªè§„åˆ™çš„ confidence, å¦‚æœ confidence >= min_confidence å°±åŠ å…¥åˆ°é˜Ÿåˆ—, å¦åˆ™ä¸æ»¡è¶³è¦æ±‚.
        å¦‚æœæŸä¸€ä¸ªè§„åˆ™ä¸æ»¡è¶³è¦æ±‚, æ¯”å¦‚ (1, 2) => (3) ä¸æ»¡è¶³è¦æ±‚, é‚£ä¹ˆå³è¾¹åŒ…å« (3) çš„è§„åˆ™éƒ½ä¸æ»¡è¶³è¦æ±‚.
        å› ä¸º confidence[(1, 2) => (3)] = P(1, 2, 3) / P(1, 2), æ˜¾ç„¶ P(1) >= P(1, 2), P(2) >= P(1, 2),
        é‚£ä¹ˆå¦‚æœ P(1, 2) ä½œä¸ºåˆ†æ¯ä¸èƒ½è®©å¼å­æ»¡è¶³è¦æ±‚, é‚£ä¹ˆåˆ†å­ä¸å˜çš„æƒ…å†µä¸‹, åˆ†æ¯å˜å¤§äº†, æ˜¾ç¤ºå¼å­ä¹Ÿä¸ä¼šæ»¡è¶³è¦æ±‚.

        ç„¶åå°†é˜Ÿåˆ—çš„æ¯ä¸€ä¸ªå…ƒç´ æ‹¿å‡ºæ¥è¿›è¡Œè®¡ç®—, ç”Ÿæˆè§„åˆ™, åˆ¤æ–­æ˜¯å¦æ»¡è¶³è¦æ±‚.

        å½“é˜Ÿåˆ—ä¸­çš„å…ƒç´ çš„ lhs å¤§å°ä¸º 1 æ—¶, è¯´æ˜æœåˆ°äº†æ ‘çš„å¶å­ç»“ç‚¹, é‚£ä¹ˆè¾“å‡ºç­”æ¡ˆ.

        åªä¿ç•™å¶å­ç»“ç‚¹çš„åŸå› æ˜¯, æ¯”å¦‚è§„åˆ™ (1) => (2, 3) æ»¡è¶³è¦æ±‚, é‚£ä¹ˆ (1, 2) => (3), (1, 3) => (2) éƒ½ä¼šæ»¡è¶³è¦æ±‚,
        æ‰€ä»¥å°±åªä¿ç•™äº†å¶å­ç»“ç‚¹çš„è§„åˆ™.

        res ä¸­å­˜çš„æ˜¯ç»“æœ,
        e.g. [{('704',): ('825', '39')}, {('39',): ('704', '825')}, {('825',): ('704', '39')}] è¡¨ç¤º
        è§„åˆ™ (704) => (825, 39), (39) => (704, 825), (825) => (704. 39).

        """
        que = collections.deque()

        lhs_tuples = frequent_items

        ignored = tuple()

        for items in itertools.combinations(frequent_items, 1):
            rhs_set = set(items)
            lhs_set = set(lhs_tuples) - rhs_set
            
            _, _, rhs_support = self.items_index(tuple(rhs_set))
            _, _, lhs_rhs_union_support = self.items_index(tuple(lhs_set.union(rhs_set)))

            if rhs_support > 0:
                confidence = lhs_rhs_union_support / rhs_support
            else:
                confidence = 0

            if confidence >= self.min_confidence:
                que.append({tuple(lhs_set): tuple(rhs_set)})
            else:
                ignored += (tuple(rhs_set))
            
        ignored = set(ignored)
        

        # ä¸é‡å¤æœæœè¿‡çš„è§„åˆ™
        has_appeared = collections.defaultdict(int)
        while len(que) > 0:
            head_dic: dict = que.popleft()
            
            if len(head_dic) == 0:
                continue

            lhs_tuples = list(head_dic.keys())[0]
            rhs_tuples = list(head_dic.values())[0]

            if len(lhs_tuples) == 1:
                # ä¸ç†Ÿæ‚‰ python ...ğŸ˜…, å› ä¸º popleft æŠŠå…ƒç´ æ‹¿å‡ºæ¥äº†, ç°åœ¨åˆè¦æ”¾å›å» ğŸ˜…
                que.append(head_dic)
                break

            for items in itertools.combinations(lhs_tuples, 1):
                rhs = rhs_tuples + items
                
                rhs_set = set(rhs)
                if len(rhs_set.intersection(ignored)) > 0:
                    continue

                if has_appeared[tuple(sorted(rhs))] > 0:
                    continue
                else:
                    has_appeared[tuple(sorted(rhs))] += 1

                lhs_set = set(lhs_tuples) - set(items)

                que.append({tuple(lhs_set): tuple(rhs_set)})
            
            # print("---")
        
        res = []
        while len(que) > 0:
            head_dic = que.popleft()
            lhs_tuples = list(head_dic.keys())[0]
            rhs_tuples = list(head_dic.values())[0]
            res.append({tuple(lhs_tuples): tuple(rhs_tuples)})
        
        return res        

    def run(self):

        candidate = {(item,): len(lines) for item, lines in self.item2line_index.items()}

        # k = 1 frequent sets
        # e.g. {1: {('1',): 5, ('3',): 7, ('4',): 5, ('6',): 4, ('2',): 6, ('5',): 3}}
        large_itemsets = {
            1: {item: count for item, count in candidate.items() if (count / self.total_line) >= self.min_support}
        }

        # ç”± k-1 è®¡ç®— k
        k = 2
        while large_itemsets[k - 1]:
            # join and prune çš„å‰ææ˜¯æœ‰åº
            itemsets_list = sorted(item for item in large_itemsets[k - 1].keys())
            c_k = utl.gen_possible_itemset(itemsets_list)

            found_itemsets = dict()

            for candidate in c_k:
                # print("candidate:", candidate)
                over_min_support, indices, _ = self.items_index(candidate)
                if over_min_support:
                    found_itemsets[candidate] = len(indices)
            large_itemsets[k] = {i: counts for (i, counts) in found_itemsets.items()}
            k += 1
        return large_itemsets


if __name__ == '__main__':
    data = "/Users/zihengzhang/KTH/ID2222-FID3016-HT22-Data-Mining/T10I4D100K.dat" # min_support = 0.01
    apriori = APriori(file_path=data, min_support=0.01, min_confidence=0.10)

    res = apriori.run()

    for i in range(1, len(res) + 1):
        print("k =", i, list(res[i].keys()))
        for item in list(res[i].keys()):
            rules = apriori.gen_rules(item)
            if len(rules) == 0:
                continue
            else:
                print("rules:", rules)

"""
1 3 4 6
2 3 4
1 2 3
2 6
2 3 4 5
2 3 5
1 2 3 4 6
1 3 4 5 6
1
"""